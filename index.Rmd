---
title: "Methods for Automating Job Submission "
author: "Cesar Sul <br> csul[at]usc.edu <br> Research Computing Associate <br> CARC at USC"
date: "2021-04-23"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Outline

- Outline
- Goes
- Here
- Coming
- Soon!

## Getting setup
- Slides are available at https://uschpc.github.io/workshop-hpc-python/   
- `git clone https://github.com/uschpc/workshop-hpc-python.git`
- Open `index.html` in browser
- examples in `examples`
- Requirements:

## Why are we here?!

- Researchers often spend time submitting jobs, checking on jobs
- When jobs complete, they decided if they want to submit more jobs
- This is time consumuing, tedious, can be error prone
- Anything repetitive can be *automated*

## What is 'Workflow Management Software'?

- Workflows are sets of tasks that depend on each other
- Workflow Management Software (WMS)
    - Tracks how jobs relate to each other
    - Tracks output files
    - Submits jobs for you
    - Resubmits if needed
    - Deletes intermediate files (if you don't need them)

## Example workflow: Music Visualizer
<div class="columns-2">
- R.I.P Daft Punk!
    - Kind of old news
- We will make them a fitting tribute
- I want to run a music visualization program
    - Song broken up into pieces
    - Each pieces represented as an image
    - Merge each piece into a movie
    - Do this for **every** song on **every** album

```{r,echo=FALSE,out.width="75%"}
knitr::include_graphics("images/daft-punk-break-up-video-screenshot.jpg")
```
</div>

## Example workflow: Music Visualizer

<div class="columns-2">

```{r,echo=FALSE,out.width="100%"}
knitr::include_graphics("images/workflow.png")
```

- There are 2 kinds of jobs
- "image generator"
    - Takes `input.flac` song file as input
    - Song is divided in into timed segments
    - Each segment is represted as series of images
    - 1 picture for every 1/60th of a second
    - Can run in any order
- `ffmpeg`
    - Merges all image files and `input.flac`
    - creates `output.mp4`
    - Can not run until **all** images are created
</div>

## Job type:`rosa_fft.py`

- "image generator" is a python script, `rosa_fft.py`
    -  `python3 rosa_fft.py -f 09Teachers.flac -i 172 -d 4 -o 09Teachers`

|option| meaning|
|---|---|
|-f | which song file to read from (doesn't have to be .flac format)|
|-i |initial time to start reading data|
|-d | how many seconds of song to read (default is 1)|
|-o | which directory to save images|


## Job type:`ffmpeg`
- ffmpeg is used to create movie file
    - `ffmpeg -threads 8 -framerate 60 -i 16Funk_Ad/images/frame%09d.png -i 16Funk_Ad.flac -pix_fmt yuv410p 16Funk_Ad.mp4`

|option| meaning|
|---|---|
|-threads| How many cpus to use when converting fiels|
|-framerate |How many pictures per second|
|-i | name or name pattern for input file(s) |
| -pix_fmt yuv410p | video encoding option?|
| output_file.mp4 | output file name|

## Job Arrays

- Built-in Slurm feature
- Use same job script for multiple jobs

rosa_fft_array.slurm:
```
#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --mem-per-cpu-1GB
#SBATCH --time=00:10:00
#SBATCH --array=0-9
module load python ffmpeg

# How many seconds to process per job
duration=4
time_index=$((SLURM_ARRAY_TASK_ID*duration))
song_file="data/symphonie_fantastique/berlioz_symphonie_2_un_bal_vals.mpr"
out_dir="output/berlioz_symphonie_2_un_bal_vals"

echo "Processing time_index:${time_index}"

python3 ./scripts/rosa_fft.py -f ${song_file} \
-i ${time_index} -t ${duration} -o ${out_dir}
```
- `$SLURM_ARRAY_TASK_ID` will be any number from 0-9

## Job Arrays

- Merge results with second job script

ffmpeg.slurm:
```
#!/bin/bash
#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=1GB
#SBATCH --time=00:10:00
module load ffmpeg

song_file="data/symphonie_fantastique/berlioz_symphonie_2_un_bal_vals.mp3"
frame_dir="output/berlioz_symphonie_2_un_bal_vals/images"
out_file="output/berlioz_symphonie_2_un_bal_vals.mp4"

ffmpeg \
-framerate 60 -i ${frame_dir}/frame%09d.png \
-i ${song_file} \
-pix_fmt yuv410p \
-threads ${SLURM_CPUS_PER_TASK} \
${out_file}
```

- This job cannot run until every element of `rosa_fft_array.slurm` completes.
- Instead of waiting, we can set a **job dependency**

## Job dependencies
- We set jobs to wait until others complete before running

manager.sh:
```
#!/bin/bash

# save 4th word using ' ' as delmiter
# AKA the job id
jid=$(sbatch examples/job_array/job_array.slurm | cut -d ' ' -f 4)

sbatch --dependency=afterok:${jid} examples/job_array/ffmpeg.slurm
```

- Using `bash` we can capture the job id

## Job array remarks

- Some basic features of a workflow manager
    - Some tasks are independent
    - Some have dependencies
    - "Template" tasks
- Easy to get set up for simple cases
- Can get out of hand quickly
- No method to handle errors
    - What if only some tasks fail?
- Large arrays can put load on scheduler    

## Workflow managers

- WMS have syntax to describe the workflow
- Usually task
    - input
    - output
    - command to generate output file
- Optional:
    - Rules if task fails
    - Compute resources for task
    - How many tasks to run in parallel
- Task order is tracked by input/output files

## SnakeMake
- A future version of this presentation will have more info on SnakeMake
- Python based
- Includes features for tracking software dependencies
- Prioritizes reproducibility
- Syntax is kind of obtuse

```
rule bwa:
    input:
        "data/genome.fa",
        "data/samples/{sample}.fastq"
    output:
        temp("mapped/{sample}.bam")
    conda:
        "envs/mapping.yaml"
    threads: 8
    shell:
        "bwa mem -t {threads} {input} | samtools view -Sb - > {output}"
```
## Makeflow

- We will use [Makeflow](http://ccl.cse.nd.edu/software/makeflow/) as an example
- [SnakeMake](https://snakemake.readthedocs.io/en/stable/tutorial/short.html) also a good alternative
- The choice is kind of arbitrary
    - A future version of this presentation may use SnakeMake
    - In general choose something that you are comfortable with
    - Something that has large userbase incase you need support

## Makeflow file

- Makeflow can be used similar to `MakeFile` used in building software
- Format is:
```
outputfile(s): inputfile(s)
# Leading whitespace below must be tab character, not spaces!
        command to generate outputfile(s)
```

- Here's an snippet:
```

./berlioz_symphonie_1_reveries_pa/berlioz_symphonie_1_reveries_pa.mp4: ./berlioz_symphonie_1_reveries_pa/images/frame000000000.png ./berlioz_symphonie_1_reveries_pa/images/frame000000001.png ./berlioz_symphonie_1_reveries_pa/images/frame000000002.png ./berlioz_symphonie_1_reveries_pa/images/frame000000003.png ./berlioz_symphonie_1_reveries_pa/images/frame000000004.png ./berlioz_symphonie_1_reveries_pa/images/frame000000005.png ./berlioz_symphonie_1_reveries_pa/images/frame000000006.png ./berlioz_symphonie_1_reveries_pa/images/frame000000007.png ./berlioz_symphonie_1_reveries_pa/images/frame000000008.png ./berlioz_symphonie_1_reveries_pa/images/frame000000009.png ./berlioz_symphonie_1_reveries_pa/images/frame000000010.png ./berlioz_symphonie_1_reveries_pa/images/frame000000011.png ./berlioz_symphonie_1_reveries_pa/images/frame000000012.png ./berlioz_symphonie_1_reveries_pa/images/frame000000013.png ./berlioz_symphonie_1_reveries_pa/images/frame000000014.png ./berlioz_symphonie_1_reveries_pa/images/frame000000015.png
    fmpeg -threads 4 -framerate 60 -i Homework/04Da_Funk/images/frame%09d.png -i data/Homework/04Da_Funk.flac -pix_fmt yuv420p  Homework/04Da_Funk/04Da_Funk.mp4

./berlioz_symphonie_1_reveries_pa/images/frame000000000.png ./berlioz_symphonie_1_reveries_pa/images/frame000000001.png ./berlioz_symphonie_1_reveries_pa/images/frame000000002.png ./berlioz_symphonie_1_reveries_pa/images/frame000000003.png ./berlioz_symphonie_1_reveries_pa/images/frame000000004.png ./berlioz_symphonie_1_reveries_pa/images/frame000000005.png ./berlioz_symphonie_1_reveries_pa/images/frame000000006.png ./berlioz_symphonie_1_reveries_pa/images/frame000000007.png ./berlioz_symphonie_1_reveries_pa/images/frame000000008.png ./berlioz_symphonie_1_reveries_pa/images/frame000000009.png ./berlioz_symphonie_1_reveries_pa/images/frame000000010.png ./berlioz_symphonie_1_reveries_pa/images/frame000000011.png ./berlioz_symphonie_1_reveries_pa/images/frame000000012.png ./berlioz_symphonie_1_reveries_pa/images/frame000000013.png
    python3 -r -f /project/hpcroot/csul/workshop-workflows/data/symphonie_fantastique/berlioz_symphonie_1_reveries_pa.mp3  -i 1 -o ./berlioz_symphonie_1_reveries_pa
```

- A few remarks
    - For more than a few files, Makeflow file is hard to read
    - Can be tedious to write by hand

## Running a Makeflow
- Assume we have a Makeflow file that converts a song
- How do we use it?
- For small number of jobs we can run locally
- You'll have to put your own songs under data
example 1
2 seconds of video

- Let's run in interactive session
- `salloc --ntasks=1 --cpus-per-task=8 --time=1:00:00 --mem-per-cpu=2GB`
- Generate makeflow file (first two seconds of song)
- `python3 examples/two_seconds/generate_makefile_params.py -f data/Homework/01Daftendirekt.flac -o examples/two_seconds/`


## Running a Makeflow
- Run the makeflow
```

makeflow berlioz_symphonie_1_reveries_pa.makeflow                                        
parsing berlioz_symphonie_1_reveries_pa.makeflow...                                                                     
local resources: 24 cores, 193123 MB memory, 5192904429 MB disk
max running local jobs: 24                                  
checking berlioz_symphonie_1_reveries_pa.makeflow for consistency...
berlioz_symphonie_1_reveries_pa.makeflow has 3 rules.
creating new log file berlioz_symphonie_1_reveries_pa.makeflow.makeflowlog...
checking files for unexpected changes...  (use --skip-file-check to skip this step)
starting workflow....
submitting job: python3 /project/hpcroot/csul/workshop-workflows/scripts/rosa_fft.py -f /project/hpcroot/csul/workshop-w
orkflows/data/symphonie_fantastique/berlioz_symphonie_1_reveries_pa.mp3 -i 1 -o ./berlioz_symphonie_1_reveries_pa
submitted job 32066
submitting job: python3 /project/hpcroot/csul/workshop-workflows/scripts/rosa_fft.py -f /project/hpcroot/csul/workshop-w
orkflows/data/symphonie_fantastique/berlioz_symphonie_1_reveries_pa.mp3 -i 0 -o ./berlioz_symphonie_1_reveries_pa
submitted job 32067
job 32066 completed  
job 32067 completed  

submitting job: ffmpeg -threads 4 -framerate 60 -i ./berlioz_symphonie_1_reveries_pa/images/frame%09d.png -i /project/hp
croot/csul/workshop-workflows/data/symphonie_fantastique/berlioz_symphonie_1_reveries_pa.mp3 -pix_fmt yuv420p ./berlioz_
symphonie_1_reveries_pa/berlioz_symphonie_1_reveries_pa.mp4                                                             
submitted job 32185                                          
job 32185 completed
nothing left to do.
```

## Running a Makeflow

- Output files should be available under `examples/makeflow/berlioz_symphonie_1_reveries_pa/`
```{r,echo=FALSE,out.width="50%"}
knitr::include_graphics("images/song.gif")
```
- We should find
    - `<song_name>.mp4`
    - `images/*.png`

## Running a Makeflow

- Output files should be available under `examples/makeflow/berlioz_symphonie_1_reveries_pa/`
```{r,echo=FALSE,out.width="50%"}
knitr::include_graphics("images/song_still.gif")
```
- We should find
    - `<song_name>.mp4`
    - `images/*.png`

## Cleaning up
- The `images` directory contains intermediate files
- Not needed after final product is complete
- Clean with `makeflow --clean=intermediates examples/two_seconds/makeflows/01Daftendirekt.makeflow`

```
makeflow --clean=intermediates berlioz_symphonie_1_reveries_pa.makeflow
parsing berlioz_symphonie_1_reveries_pa.makeflow...                                                                     
local resources: 24 cores, 193123 MB memory, 5192805270 MB disk    
max running local jobs: 24                                                                                              
checking berlioz_symphonie_1_reveries_pa.makeflow for consistency...
berlioz_symphonie_1_reveries_pa.makeflow has 3 rules.                                                                   
recovering from log file berlioz_symphonie_1_reveries_pa.makeflow.makeflowlog...
checking for old running or failed jobs...
checking files for unexpected changes...  (use --skip-file-check to skip this step)
cleaning filesystem...

deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000045.png
deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000041.png
deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000115.png
deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000078.png
deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000083.png
deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000068.png
deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000056.png
deleted ./berlioz_symphonie_1_reveries_pa/images/frame000000072.png
```
## Running a large Makeflow
- What if we have many tasks we want to run?
    -   Considering most songs are at least a few minutes long (100s of 'jobs')
- We can spread the work out over multiple compute nodes
- We need to run 2 kinds of processes
- Daemon (background process)
    - Reads the Makeflow file assigns work
- Worker process
    - Looks for Daemon and requests work

## Running a large Makeflow
- To launch daemon `makeflow -T wq examples/makeflow_workers/makeflows/01Daftendirekt.makeflow -p $PORT`

```
parsing makeflows/Blitz_it.makeflow...
local resources: 20 cores, 64334 MB memory, 5566556492 MB disk
max running remote jobs: 1000
max running local jobs: 20
checking makeflows/Blitz_it.makeflow for consistency...
makeflows/Blitz_it.makeflow has 72 rules.
submitted job 43
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 27 -o ./Blitz_it
submitted job 44
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 26 -o ./Blitz_it
submitted job 45
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 25 -o ./Blitz_it
submitted job 46
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 24 -o ./Blitz_it
submitted job 47
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 23 -o ./Blitz_it
submitted job 48
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 22 -o ./Blitz_it
submitted job 49
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 21 -o ./Blitz_it
submitted job 50
submitting job: python3 ./scripts/rosa_fft.py -f data/chirpy/Blitz_it.wav -i 20 -o ./Blitz_it
```

## Running a large Makeflow
- To launch workers `srun work_queue_worker $HOSTNAME:$PORT examples/makeflow_workers/makeflows/01Daftendirekt.makeflow`
- Also make sure to have

```
work_queue_worker: creating workspace /scratch/csul/makeflow/example/worker-268648-412
work_queue_worker: creating workspace /scratch/csul/makeflow/example/worker-268648-416
work_queue_worker: creating workspace /scratch/csul/makeflow/example/worker-268648-406
work_queue_worker: creating workspace /scratch/csul/makeflow/example/worker-268648-404
work_queue_worker: using 24 cores, 193123 MB memory, 185757288 MB disk, 0 gpus
connected to manager d06-15.hpc.usc.edu:8080 via local address 10.125.19.236:57664
work_queue_worker: using 24 cores, 193123 MB memory, 185757288 MB disk, 0 gpus
connected to manager d06-15.hpc.usc.edu:8080 via local address 10.125.19.236:57668
work_queue_worker: using 24 cores, 193123 MB memory, 185757288 MB disk, 0 gpus
connected to manager d06-15.hpc.usc.edu:8080 via local address 10.125.19.236:57672
work_queue_worker: using 24 cores, 193123 MB memory, 185757284 MB disk, 0 gpus
connected to manager d06-15.hpc.usc.edu:8080 via local address 10.125.19.234:59316
```

## Pegasus workflows

- WIP
- Pegasus version of this workflow
